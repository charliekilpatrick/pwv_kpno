{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from astropy.time import Time \n",
    "import numpy as np\n",
    "from json import dump as _dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUOMI_DIR = './suomi_data' # Location of SuomiNet data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_suomi_paths():\n",
    "    \"\"\"Create a dictionary of filepaths for locally stored SuomiNet data\n",
    "\n",
    "    Iterate over the files in SUOMI_DIR and create a dictionary of the form\n",
    "    {year (int): [paths of data files for year (str)]}\n",
    "\n",
    "    Returns:\n",
    "        suomi_data (dict): A dictionary of available SuomiNet data\n",
    "    \"\"\"\n",
    "\n",
    "    suomi_data = {}\n",
    "\n",
    "    files = [f for f in os.listdir(SUOMI_DIR)]\n",
    "    for file in files:\n",
    "        if file.endswith('.plot'):\n",
    "            if int(file[-9:-5]) not in suomi_data.keys():\n",
    "                suomi_data[int(file[-9:-5])] = []\n",
    "\n",
    "            suomi_data[int(file[-9:-5])].append(os.path.join(SUOMI_DIR, file))\n",
    "\n",
    "    return suomi_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    \"\"\"Returns contents of a SuomiNet data file as a numpy array\n",
    "\n",
    "    Expects data files from http://www.suominet.ucar.edu/data.html\n",
    "    under the \"Specific station - All year hourly\" row. The returned\n",
    "    array has column names 'date', 'pwv', 'pres', 'temp', and 'hum'.\n",
    "    \n",
    "    Args:\n",
    "        path (str): File path to be read\n",
    "\n",
    "    Returns:\n",
    "        data (numpy.ndarray): numpy array with data from file\n",
    "    \"\"\"\n",
    "    \n",
    "    data = np.genfromtxt(path, usecols=(1,2,7,8,9),\n",
    "                         names=('date', 'pwv', 'pres', 'temp', 'hum'),\n",
    "                         dtype=((np.str_, 16), float, float, float, float))\n",
    "\n",
    "    data = np.unique(data) # Sometimes SuomiNet records duplicate entries\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date_list(data_arrays):\n",
    "    \"\"\"Construct a sorted list of unique dates from a collection of arrays\n",
    "\n",
    "    Given multiple numpy arrays, create a sorted list of the unique dates\n",
    "    found in all of the arrays. Expects arrays returned by 'read_data'.\n",
    "\n",
    "    Args:\n",
    "        data_arrays (list): list of numpy arrays returned by 'read_data'\n",
    "    \n",
    "    Returns:\n",
    "        mjd (list): Sorted list of unique datetimes expressed in MJD\n",
    "    \"\"\"\n",
    "\n",
    "    datetimes = np.concatenate([array['date'] for array in data_arrays])\n",
    "    # [array['date'] for array in data_arrays] is a list of arrays each having\n",
    "    # only the datetime info; np.concatenate combines these into a single array\n",
    "    \n",
    "    unique_datetimes = np.unique(datetimes)\n",
    "    mjd = sorted([Time(t, format='isot').mjd for t in unique_datetimes])\n",
    "    \n",
    "    return mjd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_data(dates, data):\n",
    "    \"\"\"Pad and mask an array of PWV values to match a list of dates\n",
    "\n",
    "    Given an array of PWV measurements and their corresponding datetimes, pad\n",
    "    the array so that there is an entry for every datetime in a given list.\n",
    "    Expects the first argument to be a return from 'get_dates' and the second\n",
    "    second argument to be from 'read_data'.\n",
    "    \n",
    "    Returns:\n",
    "        padded_data (list): A padded data array\n",
    "    \"\"\"\n",
    "\n",
    "    mask, pwv_list = [], []\n",
    "\n",
    "    # Get datetime values from argument `data` and express them in mjd format\n",
    "    times_mjd = [Time(elt[0], format='isot').mjd for elt in data] \n",
    "\n",
    "    for date in dates:\n",
    "        if date in times_mjd:\n",
    "            # Get the corresponding PWV values\n",
    "            time = Time(date, format='mjd').isot[:-7]\n",
    "            ind = np.where(data['date'] == time)\n",
    "            pwv = data[ind]['pwv']\n",
    "\n",
    "            if len(pwv) == 1 and pwv > 0: # Eliminate cases with multiple vals\n",
    "                pwv_list.append(np.asscalar(pwv))\n",
    "                mask.append(0)\n",
    "                continue\n",
    "   \n",
    "        mask.append(1)\n",
    "        pwv_list.append(1) # Filler value\n",
    "\n",
    "    padded_data = np.ma.masked_array(data=pwv_list, mask=mask)\n",
    "    return padded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_padded_data():\n",
    "    \"\"\"Read all available SuomiNet data from file and pad the resulting arrays\n",
    "\n",
    "    Read all locally available SuomiNet data from file using `read_data`. Pad\n",
    "    the resulting arrays so that different arrays with measurments from the\n",
    "    same year are of the same length. Return the padded data in a dictionary\n",
    "    of the form {year (int): {gps reciever (str): PWV data (masked_array)}}.\n",
    "    \n",
    "    Returns:\n",
    "        all_data (dict): A composite dictionary containing padded data arrays\n",
    "    \"\"\"\n",
    "\n",
    "    all_data = dict()\n",
    "    # This dict will store SuomiNet data in the form\n",
    "    # {year (int): {gps reciever (str): PWV data (masked_array)}}\n",
    "\n",
    "    suomi_data = get_suomi_paths()\n",
    "    for yr, flist in suomi_data.items():\n",
    "        # Read data from SuomiNet file paths\n",
    "        data = {os.path.basename(f)[:4].upper(): read_data(f) for f in flist}\n",
    "\n",
    "        # Get list of unique dates\n",
    "        dates = get_date_list(list(data.values()))\n",
    "\n",
    "        # Pad the data arrays to match in length and add to all_data\n",
    "        all_data[yr] = {site: pad_data(dates, array) for site, array in data.items()}\n",
    "    \n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_padded_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class gen_fit_funcs():\n",
    "    \"\"\"This class is used to generate fit_functions relating the PWV readout\n",
    "    of recievers near Kitt Peak to the PWV on Kitt Peak. It is also used to\n",
    "    create a model of the PWV on Kitt Peak over time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Parse all locally available SuomiNet files and assign the data to\n",
    "        the self.all_data attribute as a composite dictionary of the form\n",
    "        {year (int): {gps reciever (str): PWV data (masked_array)}}.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.all_data = get_padded_data() # This may take several minutes\n",
    "        if not self.all_data:\n",
    "            raise Exception('No SuomiNet Data Found')\n",
    "\n",
    "    def create_linear_fits(self, path):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        pwv_fits = dict()\n",
    "\n",
    "        # Create a fit for each reciever\n",
    "        sites = set([key for subdict in self.all_data.values() for key in subdict])\n",
    "        for reciever in sites - set(['KITT']):\n",
    "            kdata = np.ma.masked_array([], []) # PWV data from Kitt Peak\n",
    "            odata = np.ma.masked_array([], []) # PWV data from other sites\n",
    "\n",
    "            for subdict in self.all_data.values():\n",
    "                if 'KITT' in subdict and reciever in subdict:\n",
    "                    kdata = np.ma.concatenate((kdata, subdict['KITT']))\n",
    "                    odata = np.ma.concatenate((odata, subdict[reciever]))\n",
    "\n",
    "            # Indices of data the is unmasked in both kdata and odata\n",
    "            ind = np.invert(np.logical_and(kdata.mask, odata.mask))\n",
    "\n",
    "            # Fit a first order polynomial relating odata to kdata\n",
    "            kitt_pwv = np.extract(ind, kdata.data)\n",
    "            other_pwv = np.extract(ind, odata.data)\n",
    "            pwv_fits[reciever] = list(np.polyfit(other_pwv, kitt_pwv, 1))\n",
    "\n",
    "        # Save parameters to file\n",
    "        if not path.endswith('.json'): path += '.json'\n",
    "        with open(path, 'w') as f: _dump(pwv_fits, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = gen_fit_funcs()\n",
    "test.create_linear_fits('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "   * create pwv models from individual fits\n",
    "   * mask values with pressure equal to cuttoff value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
