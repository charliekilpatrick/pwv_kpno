{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.time import Time \n",
    "from astropy.time import TimeISOT\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##gather data\n",
    "#checking multiple dates\n",
    "file_sa48_2014_new = \"SA48nrt_2014_new.plot\"\n",
    "file_sa46_2014_new = \"SA46nrt_2014_new.plot\"\n",
    "file_p014_2014_new = \"P014nrt_2014_new.plot\"\n",
    "#2014\n",
    "file_sa48_2014 = \"SA48nrt_2014.plot\"\n",
    "file_sa46_2014 = \"SA46nrt_2014.plot\"\n",
    "file_p014_2014 = \"P014nrt_2014.plot\"\n",
    "#2015\n",
    "file_kitt_2015 = \"KITTnrt_2015.plot\"\n",
    "file_sa48_2015 = \"SA48nrt_2015.plot\"\n",
    "file_sa46_2015 = \"SA46nrt_2015.plot\"\n",
    "file_p014_2015 = \"P014nrt_2015.plot\"\n",
    "file_azam_2015 = \"AZAMnrt_2015.plot\"\n",
    "#2016\n",
    "#file_kitt_2016 = \"KITTnrt_2016.plot.txt\"\n",
    "file_sa46_2016 = \"SA46nrt_2016.plot\"\n",
    "file_p014_2016 = \"P014nrt_2016.plot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#group data by year\n",
    "all_data_2014_new = (file_sa48_2014_new, file_sa46_2014_new, file_p014_2014_new)\n",
    "all_data_2014 = (file_sa48_2014, file_sa46_2014, file_p014_2014)\n",
    "all_data_2015 = (file_kitt_2015, file_sa48_2015, file_sa46_2015, file_p014_2015, file_azam_2015)\n",
    "#all_data_2016= (file_kitt_2016, file_sa46_2016, file_p014_2016)\n",
    "all_data_2016= (file_sa46_2016, file_p014_2016)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(array_files):\n",
    "    \"\"\"\n",
    "    Use np.genfromtxt to retrieve data from an array of files\n",
    "    Expects files generated from suominet: http://www.suominet.ucar.edu/data.html\n",
    "    Download data from \"Specific station - All year hourly\" row\n",
    "    \n",
    "    Input : array of files, generally one from each location\n",
    "    Output: list of arrays with noted columns\n",
    "    \"\"\"\n",
    "    \n",
    "    data = [np.genfromtxt(fil, usecols=(1,2,7,8,9),\n",
    "                          names=('date', 'pwv', 'pres', 'temp', 'hum'),\n",
    "                          dtype=((np.str_, 16), float, float, float, float)) for fil in array_files]\n",
    "    \n",
    "    for i,site in enumerate(data):\n",
    "        data[i] = np.unique(site)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date_array(data):\n",
    "    \"\"\"\n",
    "    Construct a sorted list of unique dates from an input list of \n",
    "    a data table for each site.\n",
    "    \n",
    "    Input: data - array of data for sites\n",
    "    Output: list of date & times expressed in MJD\n",
    "    \"\"\"\n",
    "    \n",
    "    datetimes = np.concatenate([site_data['date'] for site_data in data])\n",
    "    #[site_data['date'] for site_data in data] is a list of arrays each having\n",
    "    #only the datetime info; np.concatenate combines these into a single array\n",
    "    \n",
    "    unique_datetimes = np.unique(datetimes)\n",
    "    mjd = [Time(t, format='isot').mjd for t in unique_datetimes]\n",
    "    \n",
    "    return sorted(mjd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_mask(data):\n",
    "    \"\"\"\n",
    "    Set up mask, pad values so that all arrays are matching in length \n",
    "    and time stamps\n",
    "    \n",
    "    Input: data - array of data for sites\n",
    "    Output: list of arrays of 0 = not masked, 1 = masked for each possible time at each data site;\n",
    "            list of arrays of associated pwv for each time, where data are available\n",
    "    \"\"\" \n",
    "    \n",
    "    all_dates = get_date_array(data)\n",
    "    \n",
    "    full_mask = np.zeros((len(data), len(all_dates)), dtype=int)\n",
    "    full_pwv = []\n",
    "    site_num = 0\n",
    "    \n",
    "    for site in range(len(data)):\n",
    "        mask = [] \n",
    "        pwv_list = []\n",
    "        site_times = [Time(data[site][time][0], format = 'isot').mjd for time in range(len(data[site]))] \n",
    "\n",
    "        for date in all_dates:\n",
    "            if date in site_times: \n",
    "                time = Time(date, format='mjd').isot[:-7]\n",
    "                ind= np.where(data[site]['date'] == time)\n",
    "                pwv = data[site][ind]['pwv']\n",
    "\n",
    "                if len(pwv) == 1 and pwv > 0: # Eliminate cases where multiple values are found\n",
    "                    pwv_list.append(np.asscalar(pwv))\n",
    "                    mask.append(0)\n",
    "\n",
    "                else:\n",
    "                    pwv_list.append(1) # Filler value to keep positions aligned\n",
    "                    mask.append(1)\n",
    "            else:\n",
    "                mask.append(1)\n",
    "                pwv_list.append(1)\n",
    "        \n",
    "        full_mask[site_num] = mask\n",
    "        full_pwv.append(pwv_list)\n",
    "        site_num += 1      \n",
    "\n",
    "    return full_mask, full_pwv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_fit_functions():\n",
    "    \"\"\"\n",
    "    Creates a fitting function for each site provided\n",
    "    \n",
    "    Input: data - array of data for sites (use data in year with kpno data)\n",
    "    Output: fit function for each site \n",
    "    \"\"\"\n",
    "    data_2015 = get_data(all_data_2015)\n",
    "    masks_2015, pwv = create_mask(data_2015)\n",
    "    kitt_mask_2015 = masks_2015[0]\n",
    "    fit_functions = []\n",
    "\n",
    "    \n",
    "    for i, site_data in enumerate(data_2015):\n",
    "        if i > 0:\n",
    "            current_mask = masks_2015[i]\n",
    "            current_site_data = []\n",
    "            kitt_data = []\n",
    "            for i2, entry in enumerate(current_mask):\n",
    "                    if entry == 0 and kitt_mask_2015[i2] == 0:\n",
    "                        current_site_data.append(pwv[i][i2])\n",
    "                        kitt_data.append(pwv[0][i2])\n",
    "            fit = np.polyfit(current_site_data, kitt_data, 1)\n",
    "            #print current_site_data\n",
    "            #print kitt_data\n",
    "            #fit = np.polyfit(kitt_data, current_site_data, 1)\n",
    "            fit_functions.append(np.poly1d(fit))\n",
    "    \n",
    "    return fit_functions\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def estimate_pwv(mask, pwv, fit_fncs):\n",
    "    \"\"\"\n",
    "    Creates estimate for each 15-minute time slot throughout the year\n",
    "    \"\"\"\n",
    "    est_pwv = []\n",
    "    num_fit = len(mask)-1\n",
    "    #print fit_fncs[2](pwv[1][2])\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range(len(mask[0])-1): #cycle through each time\n",
    "        total_pwv = 0\n",
    "        total_sites = 0\n",
    "        for x in range(num_fit):\n",
    "            if mask[x+1][i] == 0:\n",
    "                total_pwv += fit_fncs[x+1](pwv[x][i])\n",
    "                total_sites += 1\n",
    "        if total_sites > 0:\n",
    "            est_pwv.append(total_pwv/total_sites)\n",
    "        else: \n",
    "            est_pwv.append(0)\n",
    "                \n",
    "            \n",
    "            \n",
    "        #for i, val in enumerate(mask[x]):\n",
    "        #    print x, i, val\n",
    "                        \n",
    "    \"\"\"for i in range(len(mask)):\n",
    "        for i2, val in enumerate(mask[i+1]):\n",
    "            print i2, val\"\"\"\n",
    "    \"\"\"for x in range(len(mask)):\n",
    "        for i, val in enumerate(mask[x]):\n",
    "            total_sites = 0\n",
    "            total_pwv = 0\n",
    "            if val == 0:\n",
    "                #print i, val, fit_fncs[x+1](pwv[x][i])\n",
    "                total_pwv += fit_fncs[x+1](pwv[x][i])\n",
    "                total_sites += 1\n",
    "            #if mask[1][i] == 0:\n",
    "            #    total_pwv += fit_fncs[0](pwv[1][i])\n",
    "            #    total_sites +=1\n",
    "            #if mask[2][i] == 0:\n",
    "            #   total_pwv += fit_fncs[1](pwv[2][i])\n",
    "            #    total_sites +=1\n",
    "            #if mask[3][i] == 0:\n",
    "            #    guess = fit_fncs[2](pwv[3][1])\n",
    "            #    total_pwv += guess\n",
    "            #    total_sites +=1\n",
    "            #if mask[4][i] == 0:\n",
    "            #    total_pwv += fit_fncs[3](pwv[4][i])\n",
    "            #    total_sites +=1\n",
    "        #try:\n",
    "        #    sites = total_sites\n",
    "        #except total_sites == 0:\n",
    "        #    est_pwv.append(0)\n",
    "        #else:\n",
    "        #    est_pwv.append(total_pwv / total_sites)\n",
    "        est_pwv.append(total_pwv/total_sites)\n",
    "        print total_pwv/total_sites\n",
    "            #print total_pwv\"\"\"\n",
    "\n",
    "        #return est_pwv\n",
    "    \n",
    "    #print data[0][:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.polyfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit_fncs = create_fit_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print fit_fncs[0] #first round\n",
    "print fit_fncs[1]\n",
    "print fit_fncs[2]\n",
    "print fit_fncs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print fit_fncs[0] #fixed looping issue\n",
    "print fit_fncs[1]\n",
    "print fit_fncs[2]\n",
    "print fit_fncs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print fit_fncs[0] #fixed negative pwv issue\n",
    "print fit_fncs[1]\n",
    "print fit_fncs[2]\n",
    "print fit_fncs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = np.arange(0, 5, 100)\n",
    "\n",
    "plt.plot(fit_fncs[0](sample), label='SA48')\n",
    "plt.plot(fit_fncs[1](sample), label='SA46')\n",
    "plt.plot(fit_fncs[2](sample), label='P014')\n",
    "plt.plot(fit_fncs[3](sample), label='AZAM')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.title('Fit functions')\n",
    "plt.savefig('fit_functions.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pwv[1][100:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(data_2015[0]['date'], data_2015[0]['pwv'])\n",
    "\n",
    "residual_sa48 = data_2015[0]['pwv'] - fit_fncs[1](data_2015[1]['pwv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_residual(all_data_year, fit_fn_kitt, fit_fn_site, site_num):\n",
    "    \"\"\"\n",
    "    remember: issue not with values being different sizes because they *are* different sizes, that's why we're padding them.\n",
    "    make it take the padded pwv values; only trust it to find residual if neither KPNO value nor site val == 1 after padding\n",
    "    \"\"\"\n",
    "    mask, pwv = create_mask_new(get_data(all_data_year))\n",
    "    \n",
    "    for i in range(len(mask)):\n",
    "        if mask[i][0] == 0 and mask[i][site_num] ==0:\n",
    "            print \"ok\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(mask[0])\n",
    "print len(mask[1])\n",
    "print len(mask[2])\n",
    "print len(mask[3]) #check to make sure each is same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "est_pwv = estimate_pwv(mask, pwv, fit_fncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print est_pwv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_residual(data_2015, fit_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(residual_sa48, data_2015[0]['pwv'], 'o', alpha=0.2)\n",
    "plt.ylim(-5, 35)\n",
    "plt.xlabel('SA48-KPNO [mm]')\n",
    "plt.ylabel('Actual KPNO PWV [mm]')\n",
    "plt.title('Residual Plot, SA48')\n",
    "#plt.savefig('residual_sa48.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "residual_sa48 = data_2015[0]['pwv'] - fit_fncs[1](data_2015[1]['pwv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([0, 0, 0, 1], [1, 2, 3, 4]),\n",
       " {'site2': ([0, 1, 1, 1], [5, 6, 7, 8]),\n",
       "  'site3': ([0, 0, 1, 1], [9, 3, 2, 4])})"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test = {'site1': ([0, 0, 0, 1], [1, 2, 3, 4]),\n",
    "        'site2': ([0, 1, 1, 1], [5, 6, 7, 8]),\n",
    "        'site3': ([0, 0, 1, 1], [9, 3, 2, 4])}\n",
    "\n",
    "x = test['site1']\n",
    "del test['site1']\n",
    "x, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test():\n",
    "    for x in range(7):\n",
    "        yield x, 5\n",
    "        \n",
    "(0, 5) in test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
