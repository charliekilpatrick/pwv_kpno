{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os.path import basename as _basename\n",
    "from astropy.time import Time \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##gather data\n",
    "#checking multiple dates\n",
    "file_sa48_2014_new = \"suomi_data/SA48nrt_2014_new.plot\"\n",
    "file_sa46_2014_new = \"suomi_data/SA46nrt_2014_new.plot\"\n",
    "file_p014_2014_new = \"suomi_data/P014nrt_2014_new.plot\"\n",
    "#2014\n",
    "file_sa48_2014 = \"suomi_data/SA48nrt_2014.plot\"\n",
    "file_sa46_2014 = \"suomi_data/SA46nrt_2014.plot\"\n",
    "file_p014_2014 = \"suomi_data/P014nrt_2014.plot\"\n",
    "#2015\n",
    "file_kitt_2015 = \"suomi_data/KITTnrt_2015.plot\"\n",
    "file_sa48_2015 = \"suomi_data/SA48nrt_2015.plot\"\n",
    "file_sa46_2015 = \"suomi_data/SA46nrt_2015.plot\"\n",
    "file_p014_2015 = \"suomi_data/P014nrt_2015.plot\"\n",
    "file_azam_2015 = \"suomi_data/AZAMnrt_2015.plot\"\n",
    "#2016\n",
    "#file_kitt_2016 = \"KITTnrt_2016.plot.txt\"\n",
    "file_sa46_2016 = \"suomi_data/SA46nrt_2016.plot\"\n",
    "file_p014_2016 = \"suomi_data/P014nrt_2016.plot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#group data by year\n",
    "all_data_2014_new = [file_sa48_2014_new, file_sa46_2014_new, file_p014_2014_new]\n",
    "all_data_2014 = [file_sa48_2014, file_sa46_2014, file_p014_2014]\n",
    "all_data_2015 = [file_kitt_2015, file_sa48_2015, file_sa46_2015, file_p014_2015, file_azam_2015]\n",
    "#all_data_2016= (file_kitt_2016, file_sa46_2016, file_p014_2016)\n",
    "all_data_2016= [file_sa46_2016, file_p014_2016]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    \"\"\"Returns SuomiNet data from a file path as a numpy array\n",
    "\n",
    "    Expects data files from http://www.suominet.ucar.edu/data.html\n",
    "    under the \"Specific station - All year hourly\" row. The returned\n",
    "    array has column names 'date', 'pwv', 'pres', 'temp', and 'hum'.\n",
    "    \n",
    "    Args:\n",
    "        path (str): File path to be read\n",
    "\n",
    "    Returns:\n",
    "        data (numpy.ndarray): Numpy array with data from file\n",
    "    \"\"\"\n",
    "    \n",
    "    data = np.genfromtxt(path, usecols=(1,2,7,8,9),\n",
    "                         names=('date', 'pwv', 'pres', 'temp', 'hum'),\n",
    "                         dtype=((np.str_, 16), float, float, float, float))\n",
    "\n",
    "    data = np.unique(data) # Remove duplicate entries\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date_list(*data_arrays):\n",
    "    \"\"\"Construct a sorted list of unique dates from a collection of arrays\n",
    "\n",
    "    Given multiple numpy arrays, create a sorted list of the unique dates found\n",
    "    in all of the arrays. Expects arrays returned by 'get_data'.\n",
    "    \n",
    "    Args:\n",
    "        data_arrays (numpy.ndarray): Numpy array returned by 'get_data'\n",
    "    \n",
    "    Returns:\n",
    "        mjd (list): Sorted list of unique datetimes expressed in MJD\n",
    "    \"\"\"\n",
    "\n",
    "    datetimes = np.concatenate([array['date'] for array in data_arrays])\n",
    "    # [array['date'] for array in data_arrays] is a list of arrays each having\n",
    "    # only the datetime info; np.concatenate combines these into a single array\n",
    "    \n",
    "    unique_datetimes = np.unique(datetimes)\n",
    "    mjd = sorted([Time(t, format='isot').mjd for t in unique_datetimes])\n",
    "    \n",
    "    return mjd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_data(dates, data):\n",
    "    \"\"\"Pad and mask an array of PWV values to match a list of dates\n",
    "\n",
    "    Given an array of PWV measurments and their corresponding datetimes, pad\n",
    "    the array so that there is an entry for every datetime in a given list.\n",
    "    Expects the first argument to be a return from 'get_dates' and the second\n",
    "    second argument to be from 'get_data'.\n",
    "    \n",
    "    Args:\n",
    "        dates (list): A list of unique datetimes returned by 'get_dates'\n",
    "        data  (numpy.ndarray): An array returned by 'get_data'\n",
    "    \n",
    "    Returns:\n",
    "        padded_data (list): A padded data array\n",
    "    \"\"\"\n",
    "\n",
    "    mask, pwv_list = [], []\n",
    "\n",
    "    # Get the times for the current site and express them in mjd format\n",
    "    times_mjd = [Time(elt[0], format='isot').mjd for elt in data] \n",
    "\n",
    "    for date in dates:\n",
    "        if date in times_mjd:\n",
    "            time = Time(date, format='mjd').isot[:-7]\n",
    "            ind = np.where(data['date'] == time)\n",
    "            pwv = data[ind]['pwv']\n",
    "\n",
    "            if len(pwv) == 1 and pwv > 0: # Eliminate cases with multiple values\n",
    "                pwv_list.append(np.asscalar(pwv))\n",
    "                mask.append(0)\n",
    "                continue\n",
    "\n",
    "        mask.append(1)\n",
    "        pwv_list.append(1) # Filler value\n",
    "\n",
    "    padded_data = np.ma.masked_array(data=pwv_list, mask=mask)\n",
    "    return padded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_data(files):\n",
    "    \"\"\"Combine the data from a list of file paths into a single masked array\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(files, list) or not files:\n",
    "        raise Exception('Argument must be a non-empty list')\n",
    "\n",
    "    # Seperate the kitt data from other data\n",
    "    try:\n",
    "        # Get file paths\n",
    "        kitt_path = next(f for f in files if _basename(f)[:4].upper()=='KITT')\n",
    "        other_paths = list(set(files) - set([kitt_path]))\n",
    "        \n",
    "        # Read data from file paths\n",
    "        kitt_data = get_data(kitt_path)\n",
    "        other_data = [get_data(f) for f in other_paths]\n",
    "        \n",
    "        # Get list of unique dates\n",
    "        dates = get_date_list(kitt_data, *other_data)\n",
    "        \n",
    "        # Pad the KITT data.\n",
    "        kitt_padded = pad_data(dates, kitt_data)\n",
    "        if not other_data: return kitt_padded\n",
    "        \n",
    "        # Pad the other data\n",
    "        padded_list = [pad_data(dates, site) for site in other_data]\n",
    "        other_padded = np.ma.mean(padded_list, 0)\n",
    "        \n",
    "        # Combine the data arrays\n",
    "        data, mask = [], []\n",
    "        for i, val in enumerate(kitt_padded.data):\n",
    "            if not kitt_padded.mask[i]:\n",
    "                data.append(val)\n",
    "                mask.append(False)\n",
    "\n",
    "            elif not other_padded.mask[i]:\n",
    "                data.append(other_padded.data[i])\n",
    "                mask.append(False)\n",
    "\n",
    "            else:\n",
    "                data.append(1)\n",
    "                mask.append(True)\n",
    "\n",
    "        combined_array = np.ma.masked_array(data=data, mask=mask)\n",
    "        \n",
    "        return dates, combined_array\n",
    "\n",
    "    except StopIteration:\n",
    "        other_data = [get_data(f) for f in files]\n",
    "        dates = get_date_list(*other_data)\n",
    "        padded_list = [pad_data(dates, site) for site in other_data]\n",
    "        other_padded = np.ma.mean(padded_list, 0)\n",
    "        return dates, other_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data = [7.5 7.5 7.05 ..., 11.9 10.399999999999999 11.3],\n",
       "             mask = [False False False ..., False False False],\n",
       "       fill_value = 1e+20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_data(all_data_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
